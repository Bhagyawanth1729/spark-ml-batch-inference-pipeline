{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWOErSxkoepY",
        "outputId": "5bf6e1b9-e0b4-431c-bacf-ebfd7bb38742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated 50000 rows at telco_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import argparse\n",
        "\n",
        "def generate_dataset(output_path, num_rows):\n",
        "    headers = [\n",
        "        \"customer_id\",\n",
        "        \"gender\",\n",
        "        \"SeniorCitizen\",\n",
        "        \"Partner\",\n",
        "        \"Dependents\",\n",
        "        \"tenure\",\n",
        "        \"PhoneService\",\n",
        "        \"MultipleLines\",\n",
        "        \"InternetService\",\n",
        "        \"OnlineSecurity\",\n",
        "        \"OnlineBackup\",\n",
        "        \"event_date\"\n",
        "    ]\n",
        "\n",
        "    genders = [\"Male\", \"Female\"]\n",
        "    yes_no = [\"Yes\", \"No\"]\n",
        "    internet_services = [\"DSL\", \"Fiber optic\", \"No\"]\n",
        "    multi_lines = [\"Yes\", \"No\", \"No phone service\"]\n",
        "    online_opts = [\"Yes\", \"No\", \"No internet service\"]\n",
        "\n",
        "    start_date = datetime(2025, 12, 1)\n",
        "    num_days = 10\n",
        "\n",
        "    with open(output_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        for i in range(1, num_rows + 1):\n",
        "            cid = f\"C{i:07d}\"  # unique ID\n",
        "\n",
        "            gender = random.choice(genders)\n",
        "            senior = random.choice([0, 1])\n",
        "            partner = random.choice(yes_no)\n",
        "            dependents = random.choice(yes_no)\n",
        "            tenure = random.randint(0, 72)\n",
        "\n",
        "            phone = random.choice(yes_no)\n",
        "            if phone == \"No\":\n",
        "                multiline = \"No phone service\"\n",
        "            else:\n",
        "                multiline = random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "            internet = random.choice(internet_services)\n",
        "            if internet == \"No\":\n",
        "                online_sec = \"No internet service\"\n",
        "                online_bkp = \"No internet service\"\n",
        "            else:\n",
        "                online_sec = random.choice([\"Yes\", \"No\"])\n",
        "                online_bkp = random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "            event_date = (start_date + timedelta(days=random.randint(0, num_days))).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            row = [\n",
        "                cid, gender, senior, partner, dependents, tenure,\n",
        "                phone, multiline, internet, online_sec, online_bkp, event_date\n",
        "            ]\n",
        "            writer.writerow(row)\n",
        "\n",
        "    print(f\"✅ Generated {num_rows} rows at {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Generate Telco-style CSV dataset for Spark batch inference\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Output CSV file path\")\n",
        "    parser.add_argument(\"--rows\", type=int, default=1000, help=\"Number of rows to generate\")\n",
        "\n",
        "    # Provide default arguments for execution within a Colab notebook\n",
        "    # In a real command-line execution, these would be passed via `python script.py --output data.csv --rows 500`\n",
        "    args = parser.parse_args([\"--output\", \"telco_dataset.csv\", \"--rows\", \"50000\"]) # Example values\n",
        "    generate_dataset(args.output, args.rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"telco_dataset.csv\").head()"
      ],
      "metadata": {
        "id": "2Of-JvVbozi8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.customer_id.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOdz_OWgo7oh",
        "outputId": "0edc9c68-d81c-4f09-8cc1-c18453c276a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92AlmsUgpC1J",
        "outputId": "e0077b28-ad2f-4c64-d435-359670921f6c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ss3Ej3gpOpg",
        "outputId": "e6c08bdb-6888-428b-b7d2-377f1d7e096f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"telco_dataset.csv\", \"r\") as f:\n",
        "    row_count = sum(1 for _ in f) - 1  # subtract header\n",
        "\n",
        "print(\"Total rows:\", row_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-YMvcwTpZMj",
        "outputId": "8c8a264f-b193-40cb-f58c-3a71adbfea85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q pyspark\n"
      ],
      "metadata": {
        "id": "C7b8HG_orOjp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TelcoTrainColab\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "d46w_uBBrPYn",
        "outputId": "84ac6586-f420-47b6-93e8-df9245b7421c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ed7e7ace120>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://dcdf6921caed:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>TelcoTrainColab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"telco_dataset.csv\")\n",
        "df.printSchema()\n",
        "df.show(5)\n",
        "print(\"Rows:\", df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w02yFhzqrXsE",
        "outputId": "4d269972-53b4-4158-8c5b-bdefdb216bb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- event_date: date (nullable = true)\n",
            "\n",
            "+-----------+------+-------------+-------+----------+------+------------+----------------+---------------+-------------------+-------------------+----------+\n",
            "|customer_id|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|     OnlineSecurity|       OnlineBackup|event_date|\n",
            "+-----------+------+-------------+-------+----------+------+------------+----------------+---------------+-------------------+-------------------+----------+\n",
            "|   C0000001|  Male|            1|    Yes|        No|    56|          No|No phone service|            DSL|                Yes|                Yes|2025-12-08|\n",
            "|   C0000002|  Male|            0|     No|       Yes|    62|          No|No phone service|             No|No internet service|No internet service|2025-12-03|\n",
            "|   C0000003|  Male|            1|    Yes|        No|    11|         Yes|              No|            DSL|                Yes|                Yes|2025-12-02|\n",
            "|   C0000004|  Male|            1|     No|       Yes|     1|         Yes|              No|    Fiber optic|                Yes|                Yes|2025-12-11|\n",
            "|   C0000005|  Male|            0|    Yes|       Yes|    47|         Yes|              No|            DSL|                 No|                 No|2025-12-05|\n",
            "+-----------+------+-------------+-------+----------+------+------------+----------------+---------------+-------------------+-------------------+----------+\n",
            "only showing top 5 rows\n",
            "Rows: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "df = df.withColumn(\"label\", (rand() > 0.5).cast(\"int\"))\n"
      ],
      "metadata": {
        "id": "hnqp8QqMs5yV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "categorical_cols = [\n",
        "    \"gender\", \"Partner\", \"Dependents\", \"PhoneService\",\n",
        "    \"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\"\n",
        "]\n",
        "numeric_cols = [\"SeniorCitizen\", \"tenure\"]\n",
        "\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\")\n",
        "    for c in categorical_cols\n",
        "]\n",
        "\n",
        "encoders = [\n",
        "    OneHotEncoder(inputCol=c + \"_idx\", outputCol=c + \"_ohe\")\n",
        "    for c in categorical_cols\n",
        "]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[c + \"_ohe\" for c in categorical_cols] + numeric_cols,\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n"
      ],
      "metadata": {
        "id": "F2wTyG8Ar1em"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df)\n"
      ],
      "metadata": {
        "id": "_nNVz9u4r4A5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/model/pipeline_model\"\n",
        "model.write().overwrite().save(model_path)\n",
        "\n",
        "print(\"✅ Model saved at\", model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQnKhmPkr6a3",
        "outputId": "2c4bbc09-a890-4a4c-9604-f3250b69510a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved at /content/model/pipeline_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlwKIQkfsFZf",
        "outputId": "10524bda-3f05-40da-a432-78db65fb1922"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineModel_3fd927ed657e"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.transform(df.limit(5))\n",
        "preds.select(\"customer_id\", \"prediction\", \"probability\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb2_gBfasGCR",
        "outputId": "efa9fef4-170d-4fd8-c4d1-894499ee3c92"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+--------------------+\n",
            "|customer_id|prediction|         probability|\n",
            "+-----------+----------+--------------------+\n",
            "|   C0000001|       0.0|[0.50200161276578...|\n",
            "|   C0000002|       0.0|[0.51375958747949...|\n",
            "|   C0000003|       1.0|[0.49887203888610...|\n",
            "|   C0000004|       1.0|[0.49637088771665...|\n",
            "|   C0000005|       0.0|[0.50865896179288...|\n",
            "+-----------+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"label\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wZSv88isTuu",
        "outputId": "a00a739b-fb39-41d3-aba7-eb2353a36ab7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    1|24924|\n",
            "|    0|25076|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Balanced Random **Labels** **bold text**"
      ],
      "metadata": {
        "id": "ynyEOw9dshr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "df = df.withColumn(\"label\", (rand() > 0.5).cast(\"int\"))\n"
      ],
      "metadata": {
        "id": "9vGpOT7usUOn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed2ZvaxNspQ_",
        "outputId": "0b4264a9-2b40-40aa-bdce-c1e4cd670dd7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[customer_id: string, gender: string, SeniorCitizen: int, Partner: string, Dependents: string, tenure: int, PhoneService: string, MultipleLines: string, InternetService: string, OnlineSecurity: string, OnlineBackup: string, event_date: date, label: int]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch inference & Parquet output**"
      ],
      "metadata": {
        "id": "uRQ8Snrdt1Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "model = PipelineModel.load(model_path)\n",
        "\n",
        "predictions = model.transform(df)\n",
        "\n",
        "result = predictions.select(\n",
        "    col(\"customer_id\"),\n",
        "    col(\"event_date\"),\n",
        "    col(\"prediction\"),\n",
        "    col(\"probability\")\n",
        ")\n",
        "\n",
        "output_path = \"/content/output_predictions\"\n",
        "\n",
        "result.write.mode(\"overwrite\") \\\n",
        "    .partitionBy(\"event_date\") \\\n",
        "    .parquet(output_path)\n",
        "\n",
        "print(\"✅ Batch inference done. Output at:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYmALeUQspzD",
        "outputId": "16f4f08c-bb67-477c-d742-ad63ad42aec8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Batch inference done. Output at: /content/output_predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.parquet(output_path).show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3kzI6iLuKgJ",
        "outputId": "671947ff-1482-4a9b-cd60-2c98f2b16c2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+--------------------+----------+\n",
            "|customer_id|prediction|         probability|event_date|\n",
            "+-----------+----------+--------------------+----------+\n",
            "|   C0000004|       1.0|[0.49637088771665...|2025-12-11|\n",
            "|   C0000015|       1.0|[0.49684819803810...|2025-12-11|\n",
            "|   C0000028|       1.0|[0.49887567753226...|2025-12-11|\n",
            "|   C0000039|       0.0|[0.50271165365204...|2025-12-11|\n",
            "|   C0000065|       1.0|[0.49574045654020...|2025-12-11|\n",
            "+-----------+----------+--------------------+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjpibVomuLAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}